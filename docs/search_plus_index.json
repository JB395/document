{"./":{"url":"./","title":"Unita 介绍","keywords":"","body":"Unita 介绍 什么是Unita Unita是一个企业级区块链解决方案。它的特点是高TPS（Transactions Per Second）和低交易确认时间，让DApp（去中心应用）能够适用于更多的商业场景。同时，通过使用SCAR（Scalable Consensus Algorithm）共识算法，将存储和网络资源的消耗最小化，从而降低运营成本。它是基于开源项目Qtum进行开发的，因此能够兼容Bitcoin的UTXO数据结构和Ethereum的Solidity智能合约。 相关资源 工具：主页、网络状态、浏览器、测试币申领、一键发链。 文档：English、中文。 路线图 开发区块链系统，包含SCAR共识。（完成） 搭建相关工具，包括网络状态、浏览器、测试币申领、一键发链等。（完成） 开发应用模板，展示如何基于Unita搭建商业应用。（进行中） 将Unita上传至云服务供应商，例如AWS、Google Cloud，从而让系统部署更为便捷。（待办） 开发跨链解决方案，Canal。（待办） 开发数据上链解决方案，DDAO。（待办） 开设课程，指导如何在Unita上进行开发。（待办） "},"SCAR-Consensus/":{"url":"SCAR-Consensus/","title":"SCAR：一种可伸缩共识算法","keywords":"","body":"SCAR：一种可伸缩共识算法 背景介绍 诸如PoW（Proof of Work）、PoS（Proof of Stake）等传统的区块链公式算法，为了减少分叉保证网络的稳定性，通常区块的间隔在10秒以上。例如Ethereum的区块间隔时间是15秒，Qtum是144秒，Bitcoin是10分钟。过高的区块间隔时间，导致了用户等待交易确认的时间较长，不利于实时支付等应用。 而一些联盟链的共识算法，例如EOS的DPoS [1]（Delegated Proof of Stake）、Parity的Aura [2]（Authority Round）等，通过投票选出超级节点来执行共识算法，可以将区块间隔时间降到甚至1秒以内。但这样带来的问题就是block的数量过多，对网络带宽和数据存储都带来了很大的压力。运行一个全节点，甚至仅下载block header的轻节点，都对节点设备的性能有较高的要求。 对于区块链的大多数商业应用而言，如征信上链、商品溯源等，对于区块链的写操作通常是周期性的。即每天的部分时间交易量较大，其余时间交易量小。对于这样的场景，如果始终维持高速的区块产出，对于网络和存储资源都是较大的浪费，而仅需要保证在网络高峰时段系统有较高的性能即可。 因此，我们提出了 SCAR（Scalable Consensus Algorithm）可伸缩共识算法。SCAR的思想是根据区块链网络的负载，动态地调节参数，在高性能和低负载之间找到平衡，从而实现性能可伸缩。 相关共识算法介绍 PoW，Bitcoin为代表。节点提供算力，通过大量的计算，产生新的block。算力越高，产生block的速度越快。计算难度每2016个block调整一次，保证在全网算力变化的情况下，block时间间隔保持在10分钟左右。由于block间隔时间长，且每个block的大小限制在 1 MB，所以当交易量大的时候，网络会发生严重拥堵。 PoS，Qtum为代表。节点提供token，通过少量计算，产生新的block。token数额越大，产生block的速度越快。计算难度也会定期调整，保证block时间间隔在144秒左右。PoS相对PoW而言，降低了对算力的要求，节省了能源。但是由于block间隔和block大小限制仍然是固定的，网络的负载固定，无法避免交易量大时候的拥堵。虽然Qtum目前可以使用DGP [3]（Decentralized Governance Protocol）协议手动地去调整block大小限制，但是这种方式略微繁琐。 PoW和PoS中，全网的所有节点都会参与到共识的竞争中来，所以区块间隔不能设置得过小。如果过小，则很容易产生分叉。即，如果计算难度设置得过低，则很容易出现多个节点在同一时刻产出新的block的情况。 DPoS、Tendermint等联盟链共识算法，则通过投票得到的超级节点来执行共识。由于参与共识的节点数较少，则区块间隔可以设置得很小。比如EOS的block间隔就设置成了0.5s。过短的区块间隔对带宽和硬盘都是很大的压力，在交易量少的时候也是一种资源浪费。EOS从今年6月9日上线以来，block数量至今已达1200万，而9年前开始的Bitcoin至今也才50万个block。 SCAR 共识算法描述 以下将介绍SCAR算法的一种实现方式。这种实现方式在联盟链的基础上，通过交易量来动态地更新区块间隔，从而实现了区块链性能的可升缩。需要注意的是，SCAR算法的核心思想是根据负载动态地调整区块链的性能，所以实现方式并不局限于本文所提出的这种，更多的实现有待进一步地探索。 SCAR共识算法由三个步骤组成： 统计投票得到所有超级节点。 根据网络负载计算block间隔。 间隔时间到后，超级节点按照优先级产出block，一旦一个新的block产出，回到步骤1。 SCAR共识算法的优点在于： 由超级节点执行共识，block间隔可以极大程度缩短，交易确认快。 block间隔根据网络负载动态调整，空闲时候间隔变长，降低带宽和硬盘压力。 当低于半数的超级节点出现故障的时候，新的block仍然能够产出，系统鲁棒性强。 以下将分别描述SCAR算法的三个步骤。 节点投票 投票选出超级节点可以有多种设计。比如EOS是所有用户都能参与投票，Aura是当前的超级节点可以投票选出下一轮的超级节点。这里我们提出一种基于Qtum DGP协议的投票策略。 区块链初始化时在链上部署 DGP 的智能合约，在合约内初始化了管理席位 admin 和治理席位 gov，均以地址的形式存储。DGP 协议支持在链上通过管理席位 admin 和治理席位 gov的投票，来决定超级节点是否改变。 首先我们对管理席位和治理席位的权限和修改策略做个介绍。管理席位 admin 在决定权限时具有最多的权力，它可以参与投票增加和删除 admin，同时可以投票任命 gov；而 gov只能参与到超级节点的修改投票中。即所有提案只有具备管理席位的 admin地址才能设置，具有治理席位的 gov地址仅可参与超级节点投票。 投票的具体流程如下： 收集新的超级节点的提案，向社区公布并收集反馈； 根据社区反馈调整超级节点列表，并通过智能合约存储到区块链中，作为新的提案； 通过调用 DGP 合约的相应方法，将该提案设置为待投票的提案，此时即开启投票； 拥有管理admin和治理gov权限的地址通过向投票合约发送一笔交易来对提案进行投票； 若提案未获得足够投票则被否决，不执行修改； 若提案通过，新超级节点列表的存储地址会记录进DGP合约，并在一定数量的区块后生效，以防止出现不必要的分叉。 节点可以通过 DGP 合约来获取最新的超级节点列表。 综上所述，我们可以在链上设置 DGP 合约，通过 DGP 投票的方式来决定超级节点，并动态地存储和更新授权矿工列表。 block 间隔 block的间隔需要根据网络的负载情况动态调整，网络空闲时候间隔变长，网络繁忙时候间隔变短，从而实现动态可伸缩。这里我们提出一种block间隔的计算方法，根据近期的交易数量来进行计算，交易多则间隔变短，交易少则间隔变长。 block间隔的计算公式如下： 其中，min_interval 为最小的block时间间隔，max_interval 为最大的block时间间隔。transaction_num 为最近 m 个区块内的平均交易数，这里 m 可以为大于等于1的整数。 m、min_interval 以及 max_interval 通过共识算法预先设定或者智能合约设置。 这样设计公式的意义在于： 当交易量 transaction_num 为0时，block间隔将调整为 max_interval，此时将用系统设置的最长间隔时间来尽量在一个区块内打包更多交易，避免了存储空间的浪费； 当链上交易量 transaction_num 趋向于无穷大时，block间隔将无限趋近于 min_interval，此时将用系统设置的最短间隔时间来尽可能缓解区块链网络的交易拥塞，使得交易更快地被打包进区块； max_interval 和 min_interval 可以根据实际情况进行设置（例如用户容忍的交易延迟、超级节点的网络环境和存储性能等）。 采用这种根据网络状态动态调节区块出块时间的共识算法 SCAR，可以有效的避免在交易量小时浪费存储空间，也可以在交易量大时增大区块产生速率，及时将交易打包进区块链上，保证交易更快地被确认。链上参数的动态调整也使得区块链系统变得更加灵活，提高治理效率，降低治理难度和代价。 block 产出 当超级节点和block间隔都确定之后，节点就可以在间隔时间之后轮流产出新的block。 在某一区块链高度上，若超级节点的数量为 n 个，则 SCAR 会为每个超级节点分配不同的出块时间 block_time如下： 其中，parent_block_time 为上一个block的出块时间，block_interval 为动态计算出的区块间隔。timeout 为超时时间，用来防止某些超级节点出现故障长时间无法出块，miner_index 为索引值，在同一区块高度下，不同的授权节点miner_index 不同。下面将对具体的参数设置原因和用途做出解释。 如下图所示，假定有5个被授权的超级节点 A、B、C、D、E，他们的公钥被存储在有序列表中，即上文提及的由 DGP 投票选出并可动态维护的超级节点列表（也即矿工列表）。假定在区块链高度h1时，有序矿工列表是 [pubkey_A, pubkey_B, pubkey_C, pubkey_D, pubkey_E] ，这五个超级节点会轮流创建新的区块。 当创建新区块时，矿工会通过加密算法签名这个区块，然后将签名结果附加到区块中。通过这种方式，其他节点可以通过解密从区块中恢复出矿工的公钥来，从而通过和超级节点列表进行比对来验证该矿工是否有权创建区块。当一条链被大多数矿工签名之后，这条链可以被视作为一条永久的链。例如在上图中，从创世区块到h3高度的链是一条永久的链，因为它已经被它接下来的几位矿工D、E和A签名了。如果任何矿工想要在高度h3下面制造分叉，这一分叉则无法被绝大多数矿工所认同。 共识算法可以有效地避免分叉的发生，但至少需要 n/2+1 位超级节点保持公式算法的正常运行（n 是超级节点数量，n/2 是整数除法）。共识算法对允许创建下一个区块的矿工做出了以下定义： 一个矿工在以下情况可以创建新的区块: 它当前是被授权的； 最近的n/2个块不是由它创建的。 由上述定义可得到真正被允许创建下一区块的超级节点的方式：从当前矿工列表中去掉为最近 n/2 个块签名的节点即可。例如，在区块高度 h2 上，下一区块的矿工列表如图计算得到。 由上图过程选出了 B、C、D 三个可创建下一区块的节点后，我们只需要将超级节点列表设置为有序列表，指定它们的优先级先后，就可以避免它们为产出下一区块而竞争。公式中的 miner_index 即为排序后的矿工列表的优先级索引，排序更前的超级节点将被分配更早的 block_time，每个超级节点使用被分配的 block_time 创建新的区块，并在 block_time 到来前保持等待状态。 但超级节点模式的联盟链也面临着一个问题：部分节点的故障会导致网络效率骤降甚至瘫痪。为了避免部分节点的故障导致系统停止运行，共识加入以下策略来确保正常出块。我们在系统参数中设置了 timeout ，若一个超级节点由于故障未能成功广播新的区块，则下一个超级节点会在 timeout 时间之后取代它并正常产出区块。如下图所示，在上述5个超级节点的情况下，矿工 B 在产出高度为 h2+1 的区块时发生故障。随后，B 在超级节点列表中的下一位C ，将会在其 parent_block_time 的 block_interval+timeout 时间之后，广播其创建的新区块。 实现 SCAR算法在Unita的当前版本中已经实现。其策略是，只有当网络中有未确认交易的时候，才会产生新的block。我们计划后续根据实际使用情况进行改进。 总结 SCAR在保证区块链性能的同时，尽可能节省了带宽和硬盘的消耗，并支持动态调整链上参数，相比其他共识算法更加的高效和灵活，在大规模的商业应用中会有更大的优势。 参考文献 [1] EOS.IO Technical White Paper v2: Consensus Algorithm (BFT-DPOS). https://github.com/EOSIO/Documentation/blob/master/TechnicalWhitePaper.md, March 16, 2018 [2] Aura - Authority Round - Wiki. https://wiki.parity.io/Aura [3] Qtum区块链指南. https://docs.qtum.site/zh/Qtum-Blockchain-Guide.html "},"Canal-Cross-Chain/":{"url":"Canal-Cross-Chain/","title":"Canal：一种跨链交易解决方案","keywords":"","body":"Canal: 一种跨链交易解决方案 背景介绍 随着区块链技术的发展，基于区块链的数字货币也大量涌现。这些数字货币分布在不同的区块链网络中，无法直接进行数据互通，因此主要借助于数字货币交易所进行交易。传统的数字货币交易所多为中心化的服务，在安全性、隐私性等方面都受到挑战。而运行在链上的去中心化交易所，因为其数据透明、隐私保障、实时结算等优点，越来越受到广泛的关注。 当前提出的去中心化交易所大都只实现了同一条链上的代币交易，并不能实现跨链的数字货币交易，限制了去中心化交易所的应用场景。本文提出了一种去中心化的数字货币交易所的解决方案，使用该解决方案可以实现跨链的数字货币交易。这里我们仅阐述基本的想法，具体的设计和开发仍在进行中。 我们将这个解决方案称为运河（Canal），因为运河实现的是多个城市之间的货物运输和交易。该方案设计的初衷是，当用户使用一键发链服务发布了自己的区块链后，可以借助该解决方案实现与其他链上数字货币的兑换，从而方便数字货币的流通。 相关技术 去中心化交易所 目前提出的去中心化交易所可分为以下两类。 挂单撮合 包括0x[1]、Kyber Network[2]在内的去中心化交易所系统都属于挂单撮合交易的类型。用户通过智能合约发布自己的买单或者卖单，然后系统帮助寻找最合适的买卖单组合进行交易。这种去中心化的交易所可以看做是把原本中心化交易所的交易流程移植到了链上，交易的流程机制并未发生变化。 这种交易方式的优点如下： 交易透明：挂单数据完全公开； 资金安全：数字货币通过智能合约管理，交易完成后及时转至用户账户； 交易成本低：除了区块链gas，没有第三方费用。 缺点如下： 交易在区块链上完成，交易速度慢； 市场不活跃时，买卖双方难以达成一致，流动性变弱。 自动定价 Bancor Network[3]通过智能合约，实现了用户和数字货币资金池之间的自动定价交易。交易流程如下： 搭建交易合约，并往合约里存入一定数量的数字货币A和B作为初始时刻的资金池； 当用户需要使用A币换取B币的时候，先把A币存入合约的资金池中；然后系统会根据当前合约中的A、B币的存量计算出A至B的转换率，并把资金池中对应数量的B币转至用户账户。 如果用户不断地使用A币换取B币，则资金池中的A币增加，B币减少，从而转换率降低，即A币能换取到的B币减少。 自动定价交易的优点如下： 无需支付巨额上币费用。 用户买卖不需要挂单，可随时交易。 保证流动性，用户无需担心交易深度。 缺点如下： 需要项目方提前质押一部分币到系统中 当前只支持同一条链上的数字货币转换 跨链技术 区块链网络之间数据无法互通，极大程度的限制了区块链的应用空间。跨链技术旨在解决这一问题，实现区块链之间的数据传输。目前市场上的跨链解决方案，仅仅实现了不同区块链上价值的交换，而并未实现交易功能；即数字货币仅能按照预先约定的转换率进行转换，而不能随着市场动态变化价格。这点一定程度上阻碍了数字货币价值的自由流动，也限制了跨链技术的应用空间。 跨链的解决方案可以分为两类。 中继 一类是使用一条主链连接各个侧链，实现侧链之间的数据互通，这条主链通常称为Hub或Relay。比如Cosmos[4]、Polkadot[5]等，其基本思想大体一致： 主链采用dPoS（Delegated Proof of Stake）、PoA（Proof of Authority）等弱中心化的共识算法，即区块的产出是由少数超级节点完成的，或者可以称之为联盟链。 主链的超级节点监控侧链的数据变化，然后在主链产生相应的数据；或是监控主链数据的变化，在侧链产生相应的数据。从而实现主链和侧链数据的互通。 这种跨链模式的优点是数据传输快速高效，且可以传输链上任何形式的数据；缺点是带来了中心化，即跨链数据的准确性和完整性依赖了联盟链的超级节点。 原子交换 原子跨链交换[6]是使用区块链的脚本，实现两个区块链网络中的数字货币进行原子交换。这里原子的意思是指，交换双方在两个区块链系统上发布的两笔交易必须同时完成或同时失败。其具体步骤如下： Alice用自己的A币交换Bob拥有的B币。 Alice创建交易，将A币支付给一个输出脚本，这个脚本需要用一个Alice自己知道的key和Bob的签名才能解开。 Bob看到这笔交易后，也创建交易，将B币支付给一个输出脚本，这个脚本需要同样的key和Alice的签名才能解开。 Alice用key和签名解开Bob创建的交易，将B币转移至自己的账户地址，key会随着转移操作而上链。 Bob看到链上的key之后，使用key和自己的签名解开Alice创建的交易，并将A币转移至自己的账户地址，交换完成。 如果Alice和Bob在过程中终止操作，则两笔交易在一定时间后，会分别退还给Alice和Bob，交换失败。 这种跨链模式的优点是完全的去中心化，交换不依赖任何第三方；缺点是一次交换过程必须依赖4次交易才能完成，速度慢效率低。 算法介绍 本文提出了一种去中心化的跨链数字货币交易所解决方案。其交易流程由一个联盟链网络和多个智能合约完成。以这样一个场景为例进行说明：侧链A上的数字货币需要换成侧链B上的数字货币，我们通过主链作为中继完成这笔交易。 主链 主链采用联盟链。联盟链的超级节点通过交易所的所有用户投票得到，或其他任意方式。超级节点负责验证区块链上的所有交易，并产生新的区块。主链连接了所有需要进行交易的侧链，从而保证了数据可以进行跨链传输。同时，主链负责运行数字货币交易所需的智能合约。方案的细节将在下文中描述。 跨链 跨链部分采用中继的模式，由两个合约组成，一个部署在主链上，称之为主合约，另一个部署在侧链上，称之为子合约。子合约是用于用户在侧链上进行充币和提币的，和中心化交易所中的充提币概念一致。主合约是用来同步用户的充提币和交易记录，并且存储用户余额的。 跨链步骤如下： 充币 用户向侧链A上的子合约中存入需要兑换的数字货币A。 超级节点监听到子合约地址下的数字货币A数量变化，然后在主合约中往用户的地址下增加相应数量的代币。 交易 用户操作用主合约中自己地址下的代币调用交易接口。 接口将转换后的数字货币B转移至主合约B的用户地址下。 提币 用户向侧链B的子合约发起提币请求。 超级节点监听到侧链B上的提币请求，然后销毁主合约中用户的代币，并在侧链B上将对应数量的数字货币B转移至用户地址下。 交易 交易采用自动定价的模式，由一个智能合约组成。合约在初始化的时候，需要充入一定数量的数字货币A、B，作为资金池，从而实现A与B之间的交易。 交易的流程如下： 用户想将一定数量的数字货币A转换为数字货币B。 用户将需要转换数字货币A存入合约地址下，进入资金池。 系统根据需要转换的A的数量和当前资金池中A、B的存量，计算出能转换到的B的数量。 系统将转换到的B从系统的资金池转出到用户的地址。 步骤3中的转换计算需要遵循以下原则： 资金池内的A越少，则A到B的转换率越高。B也亦然。 不能将资金池中的任何一种数字货币用尽，否则则无法继续转换。 基于以上原则，转换的逻辑可以有多种设计。例如： 假设资金池中的数字货币A、B的存量分别为a0、b0（a0 > 0，b0 > 0），用户想要将△a（△a > 0）的数字货币A转换，得到△b（△b > 0）的数字货币B。 则能转换到的B的数量为：△b =( b0 *△a ) / (a0 + △a)。 可以看到，△b是b0的增函数，是a0的减函数，符合上文中的原则1。 可以看到，△b 实现 我们计划未来对Canal进行实现。更多详情请参见路线图。 总结 在设计的过程中，我们有两点思考。第一，我们觉得不应过分强调去中心化，而牺牲交易的效率；因为如果交易的速度太慢，则会影响用户的体验；而去中心化的需求在一个联盟链的系统中，通过投票给可信的超级节点，也是一定程度上可以满足的。第二，自动定价交易的模式在实际的使用中应该是明显优于挂单交易的，因为很多新发的数字货币交易量小流动性无法保证，而自动定价交易的模式很好地解决了流动性的问题。 参考文献 [1] 0x protocol. https://www.0xproject.com/ [2] Kyber network. https://kyber.network/ [3] Bancor. https://www.bancor.network/ [4] Cosmos. https://cosmos.network/ [5] Polkadot. https://polkadot.network/ [6] Atomic Cross-Chain Swaps. https://arxiv.org/abs/1801.09515 "},"DDAO-Data-Management/":{"url":"DDAO-Data-Management/","title":"DDAO：去中心化数据访问对象","keywords":"","body":"DDAO：去中心化数据访问对象 背景介绍 数据管理（Data Management）是指对不同类型的数据进行收集、整理、组织、存储、加工、传输、检索的各个过程，它是计算机的一个重要的应用领域。其目的之一是为了借助计算机科学地保存和管理复杂的、大量的数据，以便人们能够方便而充分地利用这些信息资源；另一目的是从大量原始的数据中抽取、推导出对人们有价值的信息，然后利用信息作为行动和决策的依据。 目前企业主要使用中心化的数据库和文件系统进行数据的管理。大型的互联网公司会自己研发相关系统，例如GFS（Google File System）、SQL Server等，并部署本地化服务。中小型公司则接入AWS、阿里云等云服务，将数据管理的任务委托给了第三方。不论是本地数据库还是云数据服务，这些中心化的数据库都有一定的应用场景，并在维护着很多公司的基础数据。 中心化存储是现行数据管理的主要解决方法，但当下全球范围内的中心化数据库和文件系统出现了严重的存储问题。企业往往通过中心化数据库和文件系统，存储其所有的信息和文件。但中心化存储方案通常会黑客成为攻击的标靶，或者毁于灾难之中。企业将会面临丢失其所有的数据资源而永不可找回。而企业对数据和文件的依赖，导致了前所未见的巨大风险，令人十分忧心。虽有些大企业，也提供了相关的云备份服务，只能多提供几个备份点而已，并没有解决根本问题。 以区块链为代表的去中心化技术为数据管理提供了一类新的解决方法。数字加密和节点共识机制的引入，保证了数据的隐私、安全和不可篡改。由于数据在网络中存了很多份，就不用担心单个节点故障带来的数据丢失，提高了安全性和可靠性。加密和分割技术则保证了数据的隐私，控制了用户数据的读取权限。同时为了保证可拓展性，使用集群技术。集群即一大组节点，共同存储和管理数据，可以加入新节点，也可拓展更多集群。 然而目前，随着大量去中心化系统的提出，开发者在选择、学习、开发、部署、维护方面都面临较高的成本。于是我们提出了DDAO（Decentralized Data Access Object），目的是希望使用一个通用的库来访问各种去中心化系统，从而进行数据的CRUD（Create, Read, Update, Delete）操作。开发者通过这一系统可以快速读写各种去中心化系统中的数据，构建自己的应用，而不必关心底层的技术实现。 相关工作 随着区块链技术和数字货币市场的发展，去中心化的数据存储、管理技术也越来越受到研究领域和投资市场的重视。 去中心化文件系统 区块链作为一个分布式的账本系统，会在每个节点都备份链上的数据，因此不适合用于存储诸如图片、视频、音频等数据量较大的文件。目前的区块链应用中，仍然将这些文件存储在开发者的服务器上。这一方式造成了应用的中心化，违背了区块链的本质意义。 去中心化文件系统的项目主要包括 IPFS（InterPlanetary File System）[1]、Swarm [2]、Storj [3] 等。其基本方式都是在文件上传的时候，将文件分割为较小的数据块，然后存储到节点上。当下载文件的时候，使用文件的hash值作为地址进行请求，然后从节点上获取所有的数据块，组合成完整的文件。通过这种方式，一个文件分散地存储在网络上的各个节点中，实现了去中心化。 这些技术面临一个问题，就是如何让网络中有更多的节点保持在线，提供下载服务。因此一些项目提出在去中心化文件系统的基础上加入节点激励的机制，从而让在线的节点能够获得收益。这样，去中心化文件系统成为了一种类似于云存储的服务，用户在上传和下载的过程中需要购买服务，用来奖励提供存储服务的节点。几个典型的项目包括 Filecoin [4]、Wolk [5]、Fluence [6]、Sia [7]。 去中心化数据库 去中心化文件系统实现了数据的去中心化存储功能，但是当用户上传数据后，无法进一步对数据进行修改和查找，限制了其在数据管理方面的应用。传统的中心化数据管理服务通常使用MySQL、Redis等数据库系统来实现数据的增删改查，因此在去中心领域中也需要类似的数据库服务。 有一些项目在去中心化数据库的领域进行研究，包括 BigchainDB [8]、Bluzelle [9]、Ties.DB [10] 等。其基本想法都是将数据库的写入请求通过交易上传至区块链，然后再用MongoDB等引擎实现数据的索引功能并响应查找请求。使用区块链来构建去中心化数据库，有效地利用了区块链成熟的去中心化系统架构，在稳定性和安全性等方面有较大优势。 这些项目当前都在起步阶段，在具体的实现成熟之前，使用智能合约作为数据库服务也是一种可行的替代方案。部分项目基于Ethereum+IPFS来搭建自己的应用，使用Solidity编写的智能合约来进行数据的管理。Solidity支持的数据结构中，包含常见的List、Map、Struct等类型，这对于常见数据管理场景已经足够适用。这些项目在 [11] 中有充分的列举。 系统描述 去中心化系统的实现方案各种各样，给开发者带来了较高的掌握成本。本文将设计一个通用库，用于连接底层的去中心化系统和上层的DApp应用，实现多种去中心化系统的CRUD功能。开发者通过这个库可以快速构建自己的数据管理应用，而不必关心底层的技术实现。同时，基于这一通用库可以搭建一套云服务，提供多种去中心化系统的在线CRUD接口，省去了开发者部署和维护去中心化系统的成本。 系统可以分为三层，分别是DDMI（Decentralized Data Management Infrastructure，去中心化数据管理设施）、DDAO和DApp（Decentralized Application），以下将分别介绍。 DDMI DDMI层将兼容各种去中心化系统，包括区块链、去中心化数据库、去中心化文件系统等。这些去中心化系统可以由开发者本地启动，也可以部署在远程服务器上，然后通过统一格式的描述符进行连接。例如 name://user:password@ip:port 格式，即通过 unita://admin:123456@127.0.0.1:13889 可以连接上本地13889端口下的Unita链，或是通过 ipfs://myname:mypasswd@192.168.1.2:8080 连接局域网内8080端口下的IPFS。 DDAO DDAO层是本文提出的核心模块，主要功能包括（1）建立各种去中心化系统的连接和（2）抽象得到具有兼容性的CRUD接口。对于不同类型的去中心化系统，将抽象成不同的接口： 对于区块链系统，将包括发送交易、查询交易、创建合约、读写合约等接口。 对于去中心化数据库系统，将包括创建、查找、插入、更新等数据库接口。 对于去中心化文件系统，将包括文件上传、下载、加密等主要接口。 此处设计需要考虑到系统的兼容性，因此仅对一些通用的功能进行抽象。同时预留发送原始命令的接口，让开发者可以请求每个系统特有的一些接口。 DApp DApp可以是运行在浏览器上JavaScript脚本，也可以是运行在服务端的程序。DApp程序本身可以存储在去中心化文件系统上，通过特定地址作为入口获取到。DApp通过实例化DDAO，连接本地或是云端的去中心化系统，并对系统进行CRUD操作，从而实现数据管理的应用。 在DApp内可以实例化多个DDAO，去连接多个不同的去中心化系统。这样可以在一个应用中与多个去中心化系统进行数据交互，实现比传统基于智能合约的DApp更为丰富的功能。例如多个区块链的数据跨链传输，或是区块链+文件系统的数据可视化（Data Visualization）展现。 应用场景 丰富的应用场景是介绍DDAO重要性的最好方式。基于DDAO，很多去中心化的应用将变得易于开发实现。 去中心化的内容分享 基于DDAO可以用来搭建一个社交、博客、图片、音乐、视频分享平台。通过使用DDAO的写接口，可以将用户发布的文字、图片、视频等内容可以存储在IPFS这类去中心化文件系统中，同时将meta data（例如内容的地址、发布时间、用户ID等）存储在智能合约或是数据库中。然后再使用DDAO的读接口，进行内容的筛选、排序、展现。这样系统的优点在于用户发布的内容去中心化存储，不可篡改。 去中心化的交易平台 基于DDAO可以实现淘宝、Amazon这样的交易平台。商家上传商品信息的时候，通过DDAO的写接口将文字和图片存储至去中心化文件系统，商品的meta data（例如价格、数量、分类、关键词等）存储在智能合约或是数据库中。用户浏览的时候使用DDAO的读接口进行商品的查找、筛选。最终通过DDAO连接区块链进行订单创建、支付、完成交易。这种平台的优点是，商品信息和交易过程更加透明，支付也更为便捷。 云存储服务的去中心化 存储服务提供商通过DDAO将信息写入区块链或数据库进行注册。用户上传文件的时候，通过购买和消耗区块链上的代币，购买存储服务，并通过DDAO上传文件至去中心化文件系统，文件的地址存储至区块链或数据库。下载的时候通过DDAO浏览文件的信息和地址，再从文件系统中下载文件。用户消耗的代币用于奖励存储服务提供商，形成完整经济生态。 实现 我们计划未来对DDAO进行实现。更多详情请参见路线图。 总结 去中心化的数据存储、管理，有着广泛的应用前景。目前由于基础设施的不完善，制约了落地应用。去中心化的数据库、文件系统，都正在开发中。可以想象到不久的将来，这些系统会被陆续实现。而DDAO也会像现在中心化系统中的DAO一样，广泛地被应用在实际开发中。 参考文献 [1] IPFS. https://ipfs.io/. [2] Swarm. https://swarm-guide.readthedocs.io/en/latest/. [3] Storj. https://storj.io/. [4] Filecoin. https://filecoin.io/. [5] Wolk. https://wolk.com/. [6] Fluence. https://fluence.one/. [7] Sia. https://sia.tech/. [8] BigchainDB. https://www.bigchaindb.com/. [9] Bluzelle. https://bluzelle.com/. [10] Ties.DB. https://tiesdb.com/. [11] Awesome IPFS. https://awesome.ipfs.io/. "},"Unita-Quick-Start/":{"url":"Unita-Quick-Start/","title":"Unita快速开始","keywords":"","body":"Unita 快速开始 Unita 是基于开源项目量子链的区块链服务商，提供多个行业可定制化的企业级应用解决方案。 Unita 以联盟链为基础，构建一主链多侧链的系统架构，结合一键发链、跨链交易、数据管理等模块以及多样化配套工具，组成一站式区块链企业服务，具有搭建快速、性能稳定、平台安全的独特优势。 我们提供了 Unita 全节点钱包、水龙头领币、区块浏览器和区块链状态显示等服务，帮助您更好地使用 Unita 。 Unita 相应资源如下： 工具：主页、钱包下载、网络状态、浏览器、测试币申领、一键发链。 文档：English、中文。 目录 下载 运行 使用 水龙头领币 浏览器查看交易 查看实时网络状态 发送交易 下载全节点钱包 进入Github下载链接,找到最新版本的 release ，根据自己的设备选择对应的客户端下载。 运行全节点钱包 我们下载完成后安装全节点钱包，安装完毕后打开。没有全节点数据的用户打开后，如下图所示，客户端会让您选择区块链数据路径，您可以使用默认路径也可自定义数据路径。 点击'ok'按钮后进入 qt 钱包的概览界面，也是启动后的默认界面。默认启动时连接 Unita 主网，并会同步主网数据，需要连接一键发链的其他区块链网络也可在'系统偏好设置'（Mac用户）中修改链的名称来实现更改（详情可参见一键发链教程）。 钱包使用 如果您拥有 Unita 代币 UNT，且拥有对应地址的私钥，您可打开 Help/Debug Window，打开 Console，输入命令 importprivkey \"unitaprivkey\" 来导入私钥，如下图所示： 如果您没有私钥，则可以通过主页的 Recieve 界面的\"REQUEST PAYMENT\"按钮获得新地址， 也可以通过 getnewaddress 命令获取新的地址，并通过命令 dumpprivkey \"unitaaddress\" 来导出私钥 此时，在钱包主页的概览界面会显示您的余额等信息： 余额（Balances） 可用余额（Avaliable） 等待中的余额（Pending） 总额（Total） 其他代币（Other Tokens） 最近交易记录（Recent Transaction） 水龙头领币 进入Unita水龙头领币界面 Unita 水龙头采用社交媒体 Twitter 和 新浪微博分享的方式申领 UNT 代币，我们首先简述一下分享 Unita 申领代币的流程： 选择您熟悉的社交媒体，登录账号 按照页面上提示的内容样式，发布对应的微博或 Twitter（Twitter 格式为 '#Unita +Unita地址'，微博格式为 '#Unita# +Unita地址'） 将该条分享的 URL 复制，粘贴到输入框中 点击'Get Unita'按钮，等待检测分享内容是否符合要求，等待代币到账 我们以新浪微博为例实际操作。 在 https://m.weibo.cn/ 中登录微博账号 （https://m.weibo.cn/是微博的Html5版，便于您获取到正确的微博链接） 登录后根据微博内容要求发布对应话题和地址 发布完成后进入到自己的主页找到发布后的那条微博，复制链接 将获取的链接粘贴入水龙头的输入框中，完成验证码验证，等待确认（获得的链接应是 https://m.weibo.cn/detail/${id} 格式） Twitter 用户操作与微博相同 注意：为了防止 UNT 的恶意过度申领，我们采取了社交媒体加验证码的验证模式，同时限制了申领数量，每次申领成功会获得50枚 UNT，一个社交媒体账号在24小时内只能申领一次，但允许同一个 Unita 地址通过不同的社交账号申领。 浏览器 从水龙头获取到代币后，您可以在浏览器界面查看您的账户状态以及交易信息。 在主页的搜索框中输入您水龙头申领代币的地址，可在该地址对应的搜索结果中找到成功申领代币的交易。 同时您可以在浏览器中查看每个区块的具体信息，查看在智能合约中发行的代币，我们还提供了丰富的图表以供大家查看区块链网络的整体状态，富豪榜和挖矿榜来查看地址余额排名和挖矿地址状态，也可通过\"Send Raw Transaction\"直接发送交易 状态显示 您可以在状态显示界面查看当前 Unita 主网网络参数与状态，其中包括最新区块高度、区块大小、tps等等信息，也可观察网络中的节点状态 发送交易（Send） 在 QT 钱包的 Send 界面可以发送交易实现转账，向指定的 Unita 地址发送指定数量的 UNT 付给（Pay To）：在此处输入想要发送的 Unita 接收地址，请注意只有 Unita 地址有效。 标签（Label）： 可选项，给上面输入的地址打标签。 金额（Amount）： 在此处输入要发送的 Unita 数额。 填写完各项后，点击发送，等待3秒后再次确认，即可将 UNT 发送至目标地址。你也可以点击下方的添加收款人同时发送到多个地址。 "},"One-Click-Launch-Chain/":{"url":"One-Click-Launch-Chain/","title":"Unita一键发链教程","keywords":"","body":"Unita一键发链教程 下载 注册登录 搭建私链 生成配置 启动私链 连接私链 种子节点 搭建联盟链 配置 启动 线上治理 关于DGP 修改矿工列表 修改系统参数 下载 从Github下载最新的安装包，安装至任意目录。 注册登录 运行unitad或者unita-qt，启动Unita主链。 打开QT钱包的 Help - Debug window - Console 或是通过unita-cli执行rpc命令。 执行getnewaddress命令，生成一个新的地址作为账户，记录下来。 执行dumpprivkey命令，获得新地址的私钥，记录下来。 打开Unita一键发链主页，点击LOGIN，进入登录页。 执行signmessage命令，使用刚才生成的地址对登陆页中的message进行签名，将签名结果填进登陆页。 点击LOGIN完成登录。 搭建私链 为了便于理解，我们先介绍如何建立自己的私链。 生成配置 点击LAUNCH A NEW CHAIN，进入发链页。填写好所有新链的信息后，点击SUBMIT发布新链。各字段的含义如下。 Chain id：链名，只支持小写字母和数字，唯一。例如mychain123。 Token name：币名，只支持大写字母和数字，唯一。例如BTC、QTX。 Description：链的描述，用来介绍该链，也用于生成创世区块。例如：my first blockchain。 Message Header：网络包头，用于在网络传输的时候区分不同的链。4字节长度，十六进制表示，即8个0-9a-f的字符，例如：1234fedc。 Algorithm：共识算法。目前仅支持PoA&SCAR共识，后续会提供更多选择。想更多了解PoA&SCAR共识，参考《SCAR：一种可伸缩共识算法》。 Miner list: PoA的矿工列表，一个或多个address，逗号分隔。我们第一步建立私链，则使用默认填入的账户地址。 Block interval、Timeout：区块间隔和默认跳过时间，在共识算法中有相关介绍，可直接使用默认值。 Default port：默认的端口地址。 Dns seed、Ip seed：新的节点在加入的时候，默认连接的网络中的种子节点。由于是私链，此处留空。 Init Reward：初始每个块的奖励。 Halving interval：奖励在多少个块后折半。 Halving times：最多折半几次。 启动私链 我们生成了一个名为xunita的链（链接），按以下步骤启动该链。 使用 unitad -chain=x 或是 在unita-qt中如下图配置重启后，启动名为xunita的链。 执行getpoaminerlist，查看矿工列表。 执行importprivkey命令，导入矿工的私钥。 执行setpoaminer命令，开始使用矿工账户挖矿。每次节点重启后需要运行该命令开启挖矿。 可以从QT钱包或是执行getblockchaininfo命令，看到block数在不断增加。 新链启动成功，试着发交易或是智能合约吧！ 连接私链 假设我们已经在机器A上启动了私链xunita并进行挖矿，这时我们需要在机器B上启动节点并接入该私链。 在机器B上使用 unitad -chain=xunita 或是 在unita-qt配置后启动链xunita的节点。 运行 addnode \"ip_A\" add 命令，连接机器A上的节点。 连接之后，可以通过getpeerinfo命令查看节点情况。 试着在两个节点之间互发交易吧！ 种子节点 区块链新节点在启动的时候可以通过连接种子节点（seed）快速地找到网络，省去了上文中addnode的步骤。种子节点可以是一个ip或是一个域名，对应的服务器上保持有节点运行。以下讲解配置种子节点的流程。 新建一条名为xxxxx的链（链接），Dns seed中填写自己的域名，或是Ip seed中填写一台自己的服务器地址。如果使用域名的话，请将域名解析到自己的服务器上。Dns seed: beta.unita.network Ip seed: 47.88.61.227 登录服务器（47.88.61.227），使用 ./unitad -chain=xxxxx 的方式启动节点root@47.88.61.227:./unitad -chain=xxxxx -daemon 配置完成，这时候使用任何机器启动xxxxx链，都会连接到种子节点获取数据。可以通过getpeerinfo看到连接上的节点。 搭建联盟链 联盟链与私链的不同之处在于，联盟链是由多位矿工共同维护的。EOS就是一个典型的联盟链：先通过竞选得到多个超级节点，然后由这些超级节点负责生产区块，并获得区块奖励。 配置 新建一个名为unitax的联盟链（链接）。相比私链，其主要的改动是miner list字段设置了3个矿工地址，地址之间以逗号分隔。 Miner list UgW1vTs3bA9pb73EeJ8N9M712w6Z7Evbru,Um8w24duUhf1XE8NVcbzn91tCeiuRWU188,UjBnjZ39N7U3vRkKoknntkkfiKzFbphZRR 启动 在种子服务器上依次启动3个节点，并且通过importprivkey和setpoaminer开启3个节点的挖矿。用getblockchaininfo可以看到区块链高度开始不断增长，系统正常运行。用getblock命令可以查看每个block的矿工。 线上治理 关于DGP DGP(Decentralized Governance Protocol)是Qtum中应用的一项技术。它允许使用区块链上的智能合约去在线修改区块链的参数，这样就不会造成软分叉或是硬分叉。 DGP工作的方式非常直接了当。首先，由DGP的一名管理员发起提议去改变某一个系统参数。随后，所有的DGP管理员可以对这个提议进行投票。如果提议收到了足够多的赞同票，则该提议中的参数修改生效。然后，提议的内容会被存储在区块链上，方便区块链的软件去获取。 很明显，DGP非常适合用来存储和更新PoA中的授权矿工列表。授权的矿工可以看做是一个公钥的列表，这个列表可以通过配置文件初始化，然后再通过DGP进行更新。但这里我们需要对DGP做一些修改从而让矿工的更新过程更加安全。 由DGP更新的矿工列表需要至少延迟n/2+1个块之后真正生效。 这里，n是更新前列表的长度，n/2是整数除法。这一机制保证了矿工列表的更新操作会在其成为区块链上的永久记录之后才真正生效。否则，如果更新操作可以被另一个分叉否定掉，则列表更新前的矿工很有可能在这个分叉下继续挖矿甚至产生硬分叉。 修改矿工列表 矿工列表的DGP部署在了地址\"0000000000000000000000000000000000000085\"上，其源码在Github上可以找到:dgp-template.sol.js。矿工列表的存储合约 minerList-dgp.sol 如下： pragma solidity ^0.4.8; contract minerList{ address[] _minerList=[  0x47210a1bacc15175bb24c3384e5d3650991a7bc4,  0xfe6e43ffb52ef746a0db8cc51cb95921c34ca0a3,  0x6cadd7aefdb363ae680fc234dcfe4c40919781d3  ];  function getMinerList() constant returns(address[] vals){ return _minerList;  } } 更新矿工的过程可以简述如下： 确定每位矿工的address，然后用gethexaddress命令得到对应的hexaddress。 将所有矿工的hexaddress填入minerList-dgp.sol中的minerList参数中，得到新的矿工列表。 编译生成minerList-dgp.sol的二进制代码，复制二进制代码，将二进制代码填入Qtum钱包中的下图位置。 得到部署后的合约地址minerListAddress，然后调用dgp-template.sol中的setInitialAdmin()和addAddressProposal(minerListAddress, 2)函数，对新的minerListAddress进行投票。 收到足够多的投票后，新的minerListAddress通过，记入进paramsHistory参数中，延迟若干个block（当前为500）后生效,执行getpoaminerlist显示如下。 修改系统参数 首先通过listcontracts命令查看目前链上有哪些合约。 其中，80-85为DGP合约，分别用于 gas_schedule、block_size、gas_price、预留、block_gas_limit、miner_list 参数的在线管理。具体方法可以参照上节更新矿工的方法。 注意：在修改参数前，务必先调用DGP合约中的setInitialAdmin()函数 可以使用createcontract命令创建新的合约，callcontract去调用合约中的函数查看返回结果，sendtocontract去向合约发送token和数据。更多合约操作请查看：Unita智能合约使用方法及说明。 "}}