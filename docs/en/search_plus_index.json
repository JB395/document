{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction gitbook init "},"SCAR-Consensus/":{"url":"SCAR-Consensus/","title":"SCAR: Scalable Consensus Algorithm","keywords":"","body":"SCAR: Scalable Consensus Algorithm Background In order to reduce the fork attack and ensure the reliability of the blockchain network, the block intervals of some well-kown blockchain consensus algorithms, like PoS and PoW, are more than 10 seconds. For example: the block time interval of Ethereum is 15 seconds, the Qtum is 144 seconds and the Bitcoin is 10 minutes. Howerver, the longer the block interval is, the longer the user will be waiting for the transaction confirmation. It is not good for real-time payment and some other applications. Some consensus algorithms of the consortium blockchain, such as DPoS(Delegated Proof of Stake) [1] and Aura (Authority Round) [2] , reduce the block interval to less than 1 second by voting for the super node to execute the consensus algorithm. But the problem with this is that the number of blocks is too large, which puts a lot of pressure on network and storage. Running a full node, or even a light node that only downloads the block header, has high requirements on the performance of the node device. For most commercial applications of blockchains, such as credit record and commodity tracking, the write operations to blockchains are usually periodic. That is to say, the trading volume is large in hours of the day, and the trading volume is small in the remaining hours. For such a scenario, if the high-speed block output is always maintained, it is a big waste for the network and storage resources, and we only ensure that the system has higher performance during the peak hours of the network. Therefore, we propose the SCAR (Scalable Consensus Algorithm). The idea of SCAR is to adjust parameters dynamically to find a balance between high performance and low load to achieve performance scalability. Related Work PoW is represented by Bitcoin. The node provides computational power to generate new blocks through a large number of calculations. The higher the power is provided, the faster the block is generated. The calculation difficulty is adjusted every 2016 blocks, ensuring that the block time interval is kept at around 10 minutes in the case of a change in the overall network computing power. Since the block interval is long and the size of each block is limited to 1 MB. Therefore, the network will be seriously congested when the transaction volume is large. PoS is represented by Qtum. The node provides a token and generates a new block with a small amount of calculation. The larger the token amount is, the faster the block is generated. The calculation difficulty will also be adjusted periodically to ensure that the block time interval is around 144 seconds. Compared with PoW, PoS is more energy efficient since it reduces the computational power requirements. However, since the block interval and the block size limit are still fixed, the load on the network is fixed, and it is impossible to avoid congestion when the transaction volume is large. Although Qtum can manually adjust the block size limit using the DGP(Decentralized Governance Protocol)[3] protocol, this approach is not easy enough. In PoW and PoS, all nodes of the whole network will participate in the consensus competition, so the block interval cannot be set too small. If it is too small, it is easy to produce a fork. In other words, if the calculation difficulty is set too low, it is easy for a plurality of nodes to generate a new block at the same time. The consortium blockchain consensus algorithm, such as DPoS and Tendermint, performs consensus by voting the super nodes. Since the number of nodes participating in the consensus is small, the block interval can be set small. For example, the EOS block interval is set to 0.5s. Too short a block interval is a great pressure on bandwidth and hard disk, and it will lead to waste of resources when the transaction volume is small. Since the launch of EOS on June 9 this year, the number of blocks has reached 12 million, but Bitcoin, which started 9 years ago, has only 500,000 blocks. Algorithm Description An implementation of the SCAR algorithm will be described below. Based on the consortium blockchain, this algorithm dynamically updates the block interval by the transaction volume. It should be noted that the core idea of the SCAR algorithm is to dynamically adjust the performance of the blockchain according to the network load, so the implementation is not limited to the one proposed in this paper, and more implementations need to be further explored. There are three steps in SCAR: Count all votes to get the super nodes. Calculate the block interval based on the network load. When the interval is over, each super node try to generate a block according to the priority. Once a new block is generated, return to step 1. The advantages of the SCAR: Consensus is implemented by the super nodes, the block interval can be greatly shortened, and the transaction confirmation is faster. The block interval is dynamically adjusted according to the network load. When the network load is reduced, the block interval becomes longer. It will reduce the bandwidth and hard disk pressure. When less than half of the super nodes are fail, the new block can still be produced, and the system is still robust. The detail of three steps of the SCAR algorithm will be described separately below. Vote for super nodes There are many ways to vote for super nodes. For example, in EOS all users can vote, and in Aura current super nodes can vote for super nodes of next round. Here we propose a voting strategy based on the Qtum DGP protocol. When a new blockchain is initialized, the DGP's smart contract is deployed on the chain, and all admins (administrators) and govs (governors) are initialized in the contract. They are stored in the form of addresses. The DGP protocol supports on-chain voting by these admins and govs to determine if the super nodes should be updated. First, we will introduce the permissions and modification strategies of the admins and govs. The admins have the highest power to determine the authority. The admins can participate in voting to add and delete admins, govs and super nodes; and the govs can only vote for super nodes. The voting process is as follows: Collect new super node proposals, publish to the community and collect feedback; Adjust the list of super nodes based on community feedback and store them in the blockchain through smart contracts as a new proposal; Call the corresponding method of the DGP contract to set the proposal to be voted, and the voting is started at this time; Every admin and gov votes on the proposal by sending a transaction to the voting contract; If the proposal does not receive enough votes, it will be rejected and no amendments will be implemented; If the proposal passes, the storage address of the new super node list will be recorded in the DGP contract and will take effect after a certain number of blocks to prevent unnecessary forks. Every node can get the latest list of super nodes through the DGP contract. In summary, we can deploy DGP contract on the blockchain, determine the super nodes by DGP voting. And then, we can store and update the list of authorized nodes dynamically . Block interval The interval of the block needs to be dynamically adjusted according to the load of the network. When the network is busy, the interval becomes shorter. We propose a calculation method of block interval in this paper, which is calculated according to the number of recent transactions. The formula for calculating the block interval is as follows: In this formula, min_interval is the minimum block time interval, and max_interval is the maximum block time interval. transaction_num is the average number of transactions in the last m blocks, and m can be an integer greater than or equal to 1. These parameters (m, min_interval, and max_interval) are pre-set by consensus algorithms or smart contract. The meaning of this formula is: When the transaction_num is 0, the block interval will be adjusted to max_interval. At this time, the maximum interval set by the system will be used to pack transactions in one block as much as possible. It can avoid waste of storage resource; When the transaction_num tends to infinity, the block interval will infinitely approach min_interval, and the shortest interval set by the system will be used to ease the transaction congestion of the blockchain network as much as possible. max_interval and min_interval can be set according to the actual situation (such as user tolerated transaction delay, super node network environment and storage performance, etc.). By using the consensus algorithm SCAR, which dynamically adjusts the block time interval of the blockchain according to the network load, it can effectively avoid wasting storage resource when the transaction volume is small; also it can increase the block generation rate when the transaction volume is large, package the transaction into the blockchain in time, and guarantee the transaction to be confirmed quickly. The dynamic adjustment of the parameters on the chain also makes the blockchain system more flexible, improves governance efficiency, and reduces the difficulty and cost of governance. Generate block After the super node and block interval are determined, the node can take turns to generate a new block after the interval. At a specific blockchain height, if the number of super nodes is n, SCAR will assign a different block time to each super node. Block_time is as follows: In this formula, parent_block_time is the block time of the previous block and block_interval is dynamically calculated. timeout is used to prevent some super nodes from failing to be out of the block for a long time. The miner_index is the index value; under the same block height, different authorization nodes have different miner_index. The specific reasons and uses of the parameter settings will be explained below. As shown in the following figure, assume that there are 5 authorized super nodes A, B, C, D, E, their public keys are stored in a ordered list, which is determined by the DGP vote mentioned above. Assume that at height h1, the ordered miners list is [pubkey_A, pubkey_B, pubkey_C, pubkey_D, pubkey_E], and the five supernodes will create new blocks in turn. When a new block is created, the miners sign the block with an encryption algorithm and then append the signature to the block. In this way, other nodes can recover the miner's public key from the block by decryption, thereby verifying whether the miner has the right to create a block by comparing with the super node list. When a chain is signed by the majority of miners, the chain can be viewed as a permanent chain. For example, in the above image, the chain from the genesis block to the height of h3 is a permanent chain because it has been signed by miners D, E and A. If any miner wants to make a fork under height h3, this fork cannot be followed by most miners. Consensus algorithms can avoid forks effectively, but at least n/2+1 super nodes need to keep the consensus algorithm running (n is the number of super nodes, n/2 is integer division). The consensus algorithm defines the miners who are allowed to create the next block: A miner can create a new block in the following situations: It is authorized currently; The last n/2 blocks were not created by it. From the above definition, which super node can generate a new block: the node signed for the nearest n/2 blocks can be removed from the current miner list. For example, at the block height h2, the list of miners in the next block is calculated as shown. After selecting the three nodes (B, C, and D) that can generate the next block, we only need to set the super node list as an ordered list, and specify their priority order to avoid them competing for the next block of production. The miner_index in the formula is the priority index of the sorted miners list. The super node with a higher order will be assigned a earlier block_time, and then each super node will use the allocated block_time to create a new block and keep wait before the block_time is over. However, the super-node mode of the consortium blockchain also faces a problem: the failure of some nodes will lead to a sudden drop in network efficiency. In order to avoid the failure of some nodes, we add the following strategy to make sure the network works. We set timeout in the system parameters. If a super node fails to broadcast a new block due to a failure, the next super node will replace it after the timeout time and generate the block. As shown in the figure below, in the case of the above five super nodes, Miner B fails when producing a block with a height of h2+1. Subsequently, B's next node C in the supernode list will broadcast the new block it created after its block_interval+timeout time of parent_block_time. Conclusion While ensuring the performance of the blockchain, SCAR saves network bandwidth and hard disk consumption as much as possible by adjusting the parameters on the blockchain dynamically. It is more efficient and flexible than other consensus algorithms, and has more advantages in large-scale commercial applications. References [1] EOS.IO Technical White Paper v2: Consensus Algorithm (BFT-DPOS). https://github.com/EOSIO/Documentation/blob/master/TechnicalWhitePaper.md, March 16, 2018 [2] Aura - Authority Round - Wiki. https://wiki.parity.io/Aura [3] Qtum区块链指南. https://docs.qtum.site/zh/Qtum-Blockchain-Guide.html "},"DDAO-Data-Management/":{"url":"DDAO-Data-Management/","title":"DDAO: Decentralized Data Access Object","keywords":"","body":"DDAO: Decentralized Data Access Object Introduction Data Management refers to the process of collecting, organizing, storing, processing, transmitting and retrieving different types of data. It is an important application area of the computer science. One of its goals is to efficiently store and manage complex, large amounts of data using computers, so that people can easily get access to the data. Another goal is to extract and derive valuable information from the data, and then use the information as a guidance for action and decision making. At present, enterprises mainly use centralized databases and file systems for data management. Large Internet companies develop their own systems, such as GFS (Google File System), SQL Server, etc., and deploy local services. Small and medium-sized companies connect to cloud services such as AWS, Aliyun, and delegate data management tasks to these third parties. Local and cloud data services have their own application scenarios and they maintain the basic data of many companies. Centralized storage is currently the main solution to data management, but there are serious storage problems in centralized databases and file systems around the world. Enterprises often store all their data and files in centralized databases and file systems. But centralized storage solutions often attract attacks from hackers, or they may be ruined by an accident. Enterprises sometimes have to face the loss of all their data resources and never get them back. Some business highly relys on data and such kind of loss may lead to huge risks. Although cloud service providers would promise to do data backup, but it has not solved the fundamental problem. Decentralization technologies, such as blockchain and IPFS, provide a new type of solutions to data management. By using encryption and consensus, data privacy and security are guaranteed. Since data are stored in a lot of nodes, there is no need to worry about data loss caused by failure of \bone single node, which improves security and reliability. Encryption and segmentation technologies control the read access and guarantee data privacy. At the same time, in order to ensure scalability, cluster technology is used. A cluster is a large group of nodes that store and manage data together, and it allows new nodes to join or expanding more clusters. However, at present, with the increasing number of decentralized systems, developers have to face high costs in selection, learning, development, deployment, and maintenance of these systems. Therefore we proposed the DDAO (Decentralized Data Access Object). Our goal is to develop a common library to access various decentralized systems with uniform interfaces, so as to perform CRUD (Create, Read, Update, Delete) operations. Through this library, developers can quickly read and write data in various decentralized systems and build their own applications without having to care about the underlying technology. Related Work With the development of blockchain technology and digital currency market, decentralized data storage and management technologies receive attentions from research fields and investment markets. Decentralized File System As a decentralized system, blockchain backs up data at every node, so it is not suitable for storing large-size files, such as pictures, videos and audios. In current blockchain applications, such kind of files are still stored in servers held by developers. This way leads to the centralization of these applications, which violates the essential meaning of blockchain. Decentralized file systems mainly include IPFS (InterPlanetary File System) [1], Swarm [2], Storj [3], and so on. Their basic method is to split the uploaded file into small pieces and then store them into nodes. When downloading the file, you can use the hash value of the file as an address to make a request to a node, and then you will get all the data pieces from the node and combine them into the whole file. In this way, one file can be separately stored in many nodes in a network, which achieves decentralization. One problem with these technologies is how to keep more nodes online to provide download services. Hence, some projects propose to add node incentive mechanisms to the decentralized file system so that online nodes can obtain revenues. In this way, the decentralized file system becomes a cloud storage service, in which users need to purchase the service during uploading and downloading processes so as to reward the nodes that provide the storage service. Several typical projects include Filecoin [4], Wolk [5], Fluence [6], and Sia [7]. Decentralized Database The decentralized file system enables decentralized storage of data, but after the data are uploaded, they cannot be further modified or retrieved, which limits its application in data management. Traditional centralized data management services usually use database systems such as MySQL or Redis to execute CRUD operations of data. Therefore, similar database services are required in the decentralized area. There are several projects having research on decentralized databases, including BigchainDB [8], Bluzelle [9], Ties.DB [10] and so on. Their basic idea is to upload database write requests to the blockchain through transactions, and then use database engines such as MongoDB to perform data indexing and process read requests. Using blockchain to build decentralized databases, effectively utilizes the mature decentralized architecture of blockchain systems, and has great advantages in stability and security. These projects are currently in their initial stages, and before their implementations mature, using smart contracts as a database service is also a viable alternative. Some projects are based on Ethereum + IPFS to develop their applications, using smart contracts written by Solidity for data management. Solidity supports data structures such as List, Map, Struct, etc., which are sufficient for common data management scenarios. These items are fully enumerated in [11]. System Description Decentralized systems have a variety of implementations, leading to high learning costs for developers. This article will design a common library for connecting upper-layer DApp applications to lower-layer decentralized systems, enabling CRUD operations for multiple decentralized systems. Developers can quickly build their own data management applications through this library without having knowledge about the underlying technology. At the same time, based on this library, a cloud service can be built to provide online CRUD interfaces of multiple decentralized systems, eliminating the cost of deploying and maintaining decentralized systems for developers. The system can be separated into three layers, namely DDMI (Decentralized Data Management Infrastructure), DDAO and DApp (Decentralized Application), which will be introduced as follows. DDMI The DDMI layer contains a variety of decentralized systems, including blockchains, decentralized databases, decentralized file systems, and more. These decentralized systems can be launched locally by the developer or deployed on a remote server, and then connected through a descriptor with uniform format. For example, the format of name://user:password@ip:port, that is, connecting to a local Qtum node with port 13889 by qtum://admin:123456@127.0.0.1:13889, or connecting to an IPFS node in LAN with 8080 port by ipfs://myname:mypasswd@192.168.1.2:8080. DDAO The DDAO layer is the core module proposed in this paper. Its main functions include (1) establishing connections to various decentralized systems, (2) abstracting to get compatible CRUD interfaces. For different types of decentralized systems, abstract interfaces are different: For blockchain systems, interfaces contain sending transactions, querying transactions, creating contracts, reading and writing contracts. For decentralized database systems, database interfaces such as create, find, insert, and update are included. For decentralized file systems, main interfaces such as file upload, download, and encryption are included. The design here needs to take into account the compatibility of different systems, so only some common functions are abstracted. At the same time, the interface used to send original commands is offered, so that developers can request some unique interfaces of each system. DApp The DApp can be JavaScript scripts running on browser or programs running on server. They may also be stored in the decentralized file system and later obtained through a specific address as an entry. The DApp initiates the DDAO instance, connects local or cloud decentralized systems, and performs CRUD operations on these systems, so as to realize data management applications. Multiple DDAO instances can be initiated within one DApp, in order to connect to multiple different decentralized systems. This allows data interaction with multiple decentralized systems in one application, enabling more features compared with traditional smart contract-based DApps. For example, cross-chain data transmission among multiple blockchains, or data visualization based on blockchain and file system. Application Scenario A large number of application scenarios is the best way to describe the value of DDAO. Based on DDAO, many decentralized applications will become easy to develop and implement. Decentralized Content Sharing DDAO can be used to build a blog, photo, music, video sharing platform. By using DDAO's write interfaces, users can publish texts, images, videos and other content to a decentralized file system such as IPFS, and then store their meta data (such as content address, release time, user ID, etc.) into a smart contract or a database. The DDAO read interfaces are used to filter, sort, and display the content. The advantage of such system is that the contents published by users is decentralized and cannot be tampered with. Decentralized Trading Platform Based on DDAO, you can build a trading platform like Taobao and Amazon. When a merchant uses DDAO write interfaces to upload its product information, the text and image are stored in a decentralized file system, and the meta data (such as price, quantity, classification, keywords, etc.) are stored in a smart contract or a database. When a customer browses the platform, DDAO read interfaces are used to search and filter products. Finally, the customer uses DDAO to connect to the blockchain to create orders, pay orders, and complete orders. The advantage of this platform is that the product information and transaction process are transparent and the payment process is convenient. Decentralized Cloud Storage Service Storage service providers register their information into a blockchain or a database via DDAO. When a user uploads a file, he needs to use blockchain tokens to purchase the service, and then uploads the file to a decentralized file system through DDAO, while the file information and address are stored in a smart contract or a database. When downloading, users browse the file information and address by using DDAO, and then download the file from the file system. The tokens consumed by the user are used to reward storage service providers, forming a complete economic ecology. Summary Decentralized data management has broad application prospects. Although, at present, decentralized databases and file systems are still under development, and immature infrastructure limits its application, it is conceivable that these systems will be implemented one after another in the near future. DDAO will also be widely used just like the DAO in current centralized systems. References [1] IPFS. https://ipfs.io/. [2] Swarm. https://swarm-guide.readthedocs.io/en/latest/. [3] Storj. https://storj.io/. [4] Filecoin. https://filecoin.io/. [5] Wolk. https://wolk.com/. [6] Fluence. https://fluence.one/. [7] Sia. https://sia.tech/. [8] BigchainDB. https://www.bigchaindb.com/. [9] Bluzelle. https://bluzelle.com/. [10] Ties.DB. https://tiesdb.com/. [11] Awesome IPFS. https://awesome.ipfs.io/. "},"One-Click-Launch-Chain/":{"url":"One-Click-Launch-Chain/","title":"Unita One-click Blockchain","keywords":"","body":"Unita One-click Blockchain Unita One-click Blockchain Download Sign up and Sign in Build Private Chain Generate Configuration Start Private Chain Connect Private Chain Seed Node Build Consortium Chain Configuration Start Online Governance About DGP Modify Miners List Modify System Parameters Download Download the latest installation package from Github and install it to any directory. Sign up and Sign in Run qtumd or qtum-qt to start the main chain of Qtum. Open the Help - Debug window - Console of QT wallet or execute the RPC command by qtum-cli. Execute the getnewaddress command, generate a new address as an account and record it. Execute the dumpprivkey command, get the private key of the new address, and record it. Open the QtumX[home page] (https://qtumx.net/), click LOGIN to enter the login page. Execute the signmessage command, use the generated address to sign the message in the login page, and fill in the login page with the result of signature. Click LOGIN to complete the login. Build Private Chain In order to make it easier to understand, we will first introduce how to build own private chain. Generate Configuration Click LAUNCH A NEW CHAIN，enter the page of release new chain.After filling in all the information of the new chain,click SUBMIT to release the new chain.The meaning of each field is as follows. Chain id:the name of the chain,only support lowercase letters and numbers,unique.Such as mychain123. Token name:the name of the token,only support capital letters and numbers,unique.Such as BTC、QTX. Description:the description of the chain,to introduce the chain,also used to generate genesis block.Such as:my first blockchain. Message Header:Network head packet,used to distinguish different chains in network transmission.4 byte length,sixteen decimal representation,8 0-9a-f characters,such as:1234fedc. Algorithm:Consensus algorithm.Only PoA consensus is supported now,more choices will be provided in the future.Want to know more about PoA,referenceQtumX technical white paper. Miner list:the list of PoA miners,one or more address,separated by commas.When we build the first private chain,use the default account. Block interval、Timeout:See the technical white paper, you can use the default value directly. Default port:The default port address. Dns seed、Ip seed:The default connection seed node in the network when new node join.Because it is a private chain,left empty here. Init Reward:Initial rewards for each block. Halving interval:The reward will be half after several blocks. Halving times:Times of half. Start Private Chain We create a chain named X（link),start the chain by the following steps. Use qtumd -chain=x or After the configuration and restart in qtum-qt as shown in the following figure,start the chain named X. Execute getpoaminerlist,see the list of miners. Execute importprivkey,import the miner's private key. Execute setpoaminer,use miner's account to mine.It needs to run this command to mine after node restarts. We can see that the number of block is increasing from the QT purse or execute getblockchaininfo command. New chain startup success,try trading or intelligent contracts！ Connect Private Chain Assuming that we have started the private chain X on the machine A and mine,then we need to start the node on the machine B and access the private chain. Execute qtumd -chain=x or do configuration to start node of X in qtum-qt on machine B. Execute addnode \"ip_A\" add,connect the node on machine A. After connecting, we can view the node situation through the getpeerinfo command. Try to trade with each other between the two nodes. Seed Node The new node of the block chain can quickly find the network by connecting the seed node (seed) at the time of startup,save the steps of addnode at the above text.The seed node can be a IP or a domain name,and there are nodes running on the corresponding servers. The following explains the process of configuring the seed node. Build a new chain named xx,（Link),fill in own domain name in Dns seed,or fill in server address in Ip seed.If you use the domain name,please parse the domain name to your server. Dns seed: beta.qtumx.net Ip seed: 116.62.70.220 Enter server（116.62.70.220）,use ./qtumd -chain=xx to start the node.root@116.62.70.220:./qtumd -chain=xx -daemon Configuration is completed,any machine starting the XX chain will connect to the seed node to get data.You can see the nodes on the connection through the getpeerinfo command. Build Consortium Chain The difference between consortium chain and private chain is that the consortium chain is maintained by many miners.EOS is a typical consortium chain:first we get multiple super nodes through the campaign,then these super nodes are responsible for producing the blocks and get the reward of the blocks. Configuration Build a new consortium chain named qtumx（Link).Compared to private chain,the main change is that the miner list field has 3 miners' addresses, separated by commas. Miner list QT65fYRCwq5tctNsVNVPNnHkwajArLFjo1,QjoHqQw5DsTniaqefuzbpuBDWW3C3qimy2,QWWdLoiHnFSNCjibCyGwbQjwtSzK5Unef3 Start Start 3 nodes on the seed server,and open mining by importprivkey and setpoaminer command.We can see that the height of block is increasing and the system is running normally by the getblockchaininfo command.We can see the miner of every block by the getblock command. Online Governance About DGP Modify Miners List Modify System Parameters "}}